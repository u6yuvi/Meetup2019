{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1a991e7f539673da033393d34767c7335318ab9a"
   },
   "source": [
    "**Agenda:**\n",
    "<br>\n",
    "For this tutorial in  Deep Learning(DL) with Pytorch, we are going to be exploring Multi Layered Perceptron architecture and learn Pytorch by implementing  algoerithms under a certain usecase.We will cover the following:\n",
    "1. Deep Learning basics with Pytorch\n",
    "2. Multilayered Perceptron (MLP) implemention on  MNIST\n",
    "<br>\n",
    "\n",
    "[Kaggle Kernel to run this notebook](https://www.kaggle.com/u6yuvi/dl-with-pytorch-mnist-classification?scriptVersionId=9612691)\n",
    "\n",
    "Lets get started !!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/mlp.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6145a827010b47e713d5bcdb6f89d8042040d75f"
   },
   "source": [
    "# **1. Deep Learning basics with Pytorch**\n",
    "<br>\n",
    "In this part we will cover the following:\n",
    "1. Learn to play with tensors on numpy and pytorch \n",
    "2. Learn to build a simple feed forward network from scratch with random data \n",
    "3. Learn to build an end to end MLP for MNIST dataset****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "22b42f1fa9df82528f39a3e2c6e0f965eaa69804"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(\"List of files\",os.listdir(\"../input\"))\n",
    "import torch\n",
    "import numpy as np\n",
    "print(\"Torch Version:\",torch.__version__)\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1e8017c3ed94f083df4e2bf071f7f5f422c40ca1"
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8f08b918b1e2513ad7c1f382cfba39b0205aba6e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def test_network(net, trainloader):\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    # Create Variables for the inputs and targets\n",
    "    inputs = Variable(images)\n",
    "    targets = Variable(images)\n",
    "\n",
    "    # Clear the gradients from all Variables\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass, then backward pass, then update weights\n",
    "    output = net.forward(inputs)\n",
    "    loss = criterion(output, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def imshow(image, ax=None, title=None, normalize=True):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    if normalize:\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(axis='both', length=0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def view_recon(img, recon):\n",
    "    ''' Function for displaying an image (as a PyTorch Tensor) and its\n",
    "        reconstruction also a PyTorch Tensor\n",
    "    '''\n",
    "\n",
    "    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
    "    axes[0].imshow(img.numpy().squeeze())\n",
    "    axes[1].imshow(recon.data.numpy().squeeze())\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "        ax.set_adjustable('box-forced')\n",
    "\n",
    "def view_classify(img, ps, version=\"MNIST\"):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    if version == \"MNIST\":\n",
    "        ax2.set_yticklabels(np.arange(10))\n",
    "    elif version == \"Fashion\":\n",
    "        ax2.set_yticklabels(['T-shirt/top',\n",
    "                            'Trouser',\n",
    "                            'Pullover',\n",
    "                            'Dress',\n",
    "                            'Coat',\n",
    "                            'Sandal',\n",
    "                            'Shirt',\n",
    "                            'Sneaker',\n",
    "                            'Bag',\n",
    "                            'Ankle Boot'], size='small');\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "It turns out neural network computations are just a bunch of linear algebra operations on *tensors*, a generalization of matrices. A vector is a 1-dimensional tensor, a matrix is a 2-dimensional tensor, an array with three indices is a 3-dimensional tensor (RGB color images for example). The fundamental data structure for neural networks are tensors and PyTorch (as well as pretty much every other deep learning framework) is built around tensors.\n",
    "\n",
    "<img src=\"images/tensor_examples.svg\" width=600px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1afe587702c9d925968dc34d4e7f515b700d9089"
   },
   "source": [
    " ## Numpy to Torch and back\n",
    "\n",
    "PyTorch has a great feature for converting between Numpy arrays and Torch tensors. Let us see how easy it is to switch between the two\n",
    "\n",
    "### Ceate a tensor using numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "35d8b903e1564ee833e2d0ed2ea00d40b61aa16e"
   },
   "outputs": [],
   "source": [
    "np_array=np.random.randn(5,3)\n",
    "print(f' Numpy array:\\n {np_array}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1d82db999b723fa737510352cf47d96a62b8d63b"
   },
   "source": [
    "### Convert to torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1cbd6fd48cf54645f924d354fc9fb5856bf1ddc1"
   },
   "outputs": [],
   "source": [
    "torch_tensor=torch.from_numpy(np_array)\n",
    "print(f'Torch tensor:\\n {torch_tensor}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "31fe8979751ba061cc81055bbc5079bed1cb0124"
   },
   "source": [
    "### Convert back to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e72bac0d8c4870f97b1d1724c0bce3fd84b50450"
   },
   "outputs": [],
   "source": [
    "torch_tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "532f4e612d823389740276fdb2f1d0c9d69cb78d"
   },
   "source": [
    "***An important thing to note here is memory is shared between the Numpy array and Torch tensor, so if you change the values in-place of one object, the other will change as well.*       \n",
    "Let see what does it mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a08bc968bbb69b18d7d376748f7a5333f931efe"
   },
   "outputs": [],
   "source": [
    "# Add 2 to PyTorch Tensor, in place\n",
    "torch_tensor.add_(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "15c233bd4f3539d1cf8c07878d01802607a6ab89"
   },
   "source": [
    "###  Numpy array matches new values from Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3d4047f95de1ca8055e276de3246da2c6a01ccee"
   },
   "outputs": [],
   "source": [
    "np_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b183396c1d82a600e1c3b1848e94e3ce5a6fbe28"
   },
   "source": [
    " ## Simple Neural Network using Pytorch \n",
    " Let us see how we can use PyTorch to build a simple neural network.\n",
    "![](images/simple_neuron.PNG)\n",
    "\n",
    "Mathematically this looks like: \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y &= f(w_1 x_1 + w_2 x_2 + b) \\\\\n",
    "y &= f\\left(\\sum_i w_i x_i +b \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "With vectors this is the dot/inner product of two vectors:\n",
    "\n",
    "$$\n",
    "h = \\begin{bmatrix}\n",
    "x_1 \\, x_2 \\cdots  x_n\n",
    "\\end{bmatrix}\n",
    "\\cdot \n",
    "\\begin{bmatrix}\n",
    "           w_1 \\\\\n",
    "           w_2 \\\\\n",
    "           \\vdots \\\\\n",
    "           w_n\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the basics covered, it's time to explore how we can use PyTorch to build a simple neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "93562b119ff2797b3660bb0968bc6c31e890b7e5"
   },
   "source": [
    "###  Generate some random data \n",
    " We will create a tensor with shape (1, 5), one row and five columns, that contains values randomly distributed according to the normal distribution with a mean of zero and standard deviation of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fd1ee538877f19c8a2cfac8ea123ecbdb2f4a94d"
   },
   "outputs": [],
   "source": [
    "# Set the random seed so things are predictable\n",
    "torch.manual_seed(7) \n",
    "features=torch.randn(1,3)\n",
    "print(f'Number of Inout features:{features.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Weights and Biases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f39730f8dbaff0834b223744d0bab6bfc516e2c"
   },
   "source": [
    "Weights = torch.randn_like(features) creates another tensor with the same shape as features, again containing values from a normal distribution.\n",
    "\n",
    "Finally, bias = torch.randn((1, 1)) creates a single value from a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3d2b5d527e0650f3d3c1942a5ee1da56bbbac7de"
   },
   "outputs": [],
   "source": [
    "n_input=features.shape[1]\n",
    "n_hidden=2\n",
    "n_output=1\n",
    "#Weights for input to hidden layer\n",
    "W1=torch.randn(n_input,n_hidden)\n",
    "W2=torch.randn(n_hidden,n_output)\n",
    "#Bias term for hidden and output layer\n",
    "B1=torch.randn(n_hidden)\n",
    "B2=torch.randn(n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cd62c805fb7363693b56ec9dbcd00a8c404adcba"
   },
   "outputs": [],
   "source": [
    "#Using a Sigmoid Activation Function\n",
    "def activation(x):\n",
    "    return(1/1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fbfeec62cfa4a35cb829897b71a4450b70ec8392"
   },
   "source": [
    "### Calculate Weight and Biases\n",
    "We will calculate the output for this multi-layer network using the weights `W1` & `W2`, and the biases, `B1` & `B2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bd98acc8aa8bb1d2fe06cb77ffd4a5054c07a40b"
   },
   "outputs": [],
   "source": [
    "h1=activation(torch.matmul(features,W1)+B1)\n",
    "print(f'Hidden Layer activations:{h1}')\n",
    "out=activation(torch.matmul(h1,W2)+B2)\n",
    "print(f'Output of the network:{out}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21b8946d94159fc86b191a82bbbb4e34d2289f53"
   },
   "source": [
    "## Building our Network\n",
    "Now we're going to build a larger network that can solve a (formerly) difficult problem, identifying text in an image using MNIST data\n",
    "For now our goal will be to build a neural network that can take one of these images and predict the digit in the image.First, let's try to build this network for this dataset using weight matrices and matrix multiplications. Then, we'll see how to do it using PyTorch's `nn` module which provides a much more convenient and powerful method for defining network architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/mnist.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d2974386321060bd66905127f3a48b9f1b177310"
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import helper\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "237092ef839e8201ecc710f53ed7154e0f865b2e"
   },
   "source": [
    "### Load Dataset \n",
    "First up, we need to get our dataset.Right now we will be using MNIST dataset which is already in`torchvision` package. The code below will download the MNIST dataset, then create training and test datasets for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "45cde9b49e2c0e1802ff640ebab0d766233e6abe"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "00ab24a0af33038559ec91ea83458558e4d574bf"
   },
   "source": [
    "We have the training data loaded into trainloader \n",
    "\n",
    "With dataloaded we make  an iterator with iter(trainloader). Later, we'll use this to loop through the dataset for training, like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9808e8dab8f56248ae40759f20b1e59dad3ede7b"
   },
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "#Printing the size of one image\n",
    "print(images[1].numpy().squeeze().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f544046855f3efd0eb1d88fb11f0e4e27318d5eb"
   },
   "outputs": [],
   "source": [
    "#Look at the image\n",
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b11c0c543d20cfb96cbb0635eea5f93e37c58cb0"
   },
   "outputs": [],
   "source": [
    "#Sigmoid Activation Function\n",
    "def activation(x):\n",
    "    return (1/(1+torch.exp(-x)))\n",
    "\n",
    "#Input 64x784\n",
    "inputs=images.view(images.shape[0],-1)\n",
    "#Number of input features-784\n",
    "n_input=inputs.shape[1]\n",
    "#Number of neurons in hidden layer-256\n",
    "n_hidden=256\n",
    "#Number of output neuron-10\n",
    "n_out=10\n",
    "#Weight at hidden neuron-784x256\n",
    "W1=torch.randn(n_input,n_hidden)\n",
    "#Bias at hidden neuron-256\n",
    "B1=torch.randn(n_hidden)\n",
    "#Weight at output neuron-256x10\n",
    "W2=torch.randn(n_hidden,n_out)\n",
    "#Bias at output neuron-10\n",
    "B2=torch.randn(n_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e494abcbcf8bf4e1210b1acdc0790ca77f826e21"
   },
   "outputs": [],
   "source": [
    "print(\"Shape of a batch of an image:\",images.shape)\n",
    "print(\"Shape of the input to the network:\",inputs.shape)\n",
    "print(\"Shape of the input features:\",n_input)\n",
    "print(\"Shape of the Weight matrix of neurons in the hidden layer\",W1.shape)\n",
    "print(\"Shape of the Bias vector of neurons in the hidden layer\",B1.shape)\n",
    "print(\"Shape of the Weight matrix of neurons in the output layer\",W2.shape)\n",
    "print(\"Shape of the Bias vector of neurons in the output layer\",W2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e751026ecf95253bf33db0462ce8bc250c082bb7"
   },
   "outputs": [],
   "source": [
    "#Hidden layer activations\n",
    "h1=activation(torch.mm(inputs,W1)+B1)\n",
    "#Output layer activations\n",
    "out=activation(torch.mm(h1,W2)+B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2cb2a0f4a6d9852da5d4811e89734c8906bbb878"
   },
   "outputs": [],
   "source": [
    "print(f'Shape of the Hidden activation of the network{h1.shape}')\n",
    "print(f'Shape of the Output of the network{out.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "66671445031ee39d4142f84c832b2ab097f6d14a"
   },
   "outputs": [],
   "source": [
    "#Let us see the network output to one of the feeded input image\n",
    "out[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 10 outputs for our network. This raw output is usually called **logits or scores**.\n",
    "<br>\n",
    "However,We want to pass in an image to our network and get out a probability distribution over the classes that tells us the likely class(es) the image belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1903f5520e57c8ca69b4252ed7a7c4d5e5beb51a"
   },
   "source": [
    "\n",
    "### Probability Distribution using Softmax\n",
    "To calculate this probability distribution, we often use the [softmax function](https://en.wikipedia.org/wiki/Softmax_function)\n",
    "$$\n",
    "\\Large \\sigma(x_i) = \\cfrac{e^{x_i}}{\\sum_k^K{e^{x_k}}}\n",
    "$$\n",
    "What this does is squish each input $x_i$ between 0 and 1 and normalizes the values to give you a proper probability distribution where the probabilites sum up to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f4d7ba5cc02acf1610fa113490099e51e84978aa"
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return(torch.exp(x)/torch.sum(torch.exp(x),dim=1).view(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bdf3ab4229b26432555148c0d1b67f6e857055e6"
   },
   "source": [
    "Let us understand what we are doing above by an example\n",
    "<br>\n",
    "Step 1:Calculating the numerator of the softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d06ddfc05e73456929293906a0ee9672cf2f45a6"
   },
   "outputs": [],
   "source": [
    "torch.exp(out[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0fd149046af107a72d73208528b3a5cf1a6eb13e"
   },
   "source": [
    "Step 2:For every predicted image output, calculate the sum over the predicted values over all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2277f07ce4566f91bf8ad70e3969f2c4790e676d"
   },
   "outputs": [],
   "source": [
    "#print(torch.sum(torch.exp(out[1:3])))\n",
    "#Dim=1 says, we want to take the sum across all columns\n",
    "torch.sum(torch.exp(out[1:3]),dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e247c285cf5dfdd02702bc79ddc8e49383bc17c1"
   },
   "source": [
    "Step3:Rearrange the sums in an order for broadcasting to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8c226fe7a4a2e9f31f63ddca18ed71959d9a139d"
   },
   "outputs": [],
   "source": [
    "torch.sum(torch.exp(out[1:3]),dim=1).view(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ecbcd104b966f3ae051d09048e7d708f992f1a41"
   },
   "source": [
    "Step 3:For every predicted image output, divide the predictions of each class with the sum over all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fce3f0e89d812e35f44a46ee5eab0fc85bf05406"
   },
   "outputs": [],
   "source": [
    "#print(torch.exp(out[1:3])/torch.sum(torch.exp(out[1:3]),dim=1))\n",
    "temp=torch.exp(out[1:3])/torch.sum(torch.exp(out[1:3]),dim=1).view(-1,1)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0973f2a30eacf6d699df25a24ce00f9487f35559"
   },
   "source": [
    "Voila!! We got the softmax output .One last thing to do is check whether the sum across all classes sum to 1 for understanding the predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5f899daaaf970fbb7b821a9cf4f70af1b00a9773"
   },
   "outputs": [],
   "source": [
    "temp.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da2f00d033b1ef41cf3941998ef34e24167a08cc"
   },
   "outputs": [],
   "source": [
    "probabilities = softmax(out)\n",
    "# Does it have the right shape? Should be (64, 10)\n",
    "print(probabilities.shape)\n",
    "# Does it sum to 1?\n",
    "#print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f9cd86feb1156d1a7ba69037197aabf876735be6"
   },
   "source": [
    "## Building our Network with Pytorch\n",
    "\n",
    "![](images/mlp_mnist.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6b0737a96ecaa7d4bcd0f6bc4592961e5ffc8e42"
   },
   "source": [
    "PyTorch provides a module `nn` that makes building networks much simpler. Here I'll show you how to build the same one as above with 784 inputs, 256 hidden units, 10 output units and a softmax output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e82cac77674746147dc9dd5d9367b21c1e02d40c"
   },
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "72a3786079aa4a387146ff066176d5af56b11b4b"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden=nn.Linear(784,256)\n",
    "        self.output=nn.Linear(256,10)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        self.softmax=nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.hidden(x)\n",
    "        x=self.sigmoid(x)\n",
    "        x=self.output(x)\n",
    "        x=self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b1546fd3ac7e6ab35a81dfee3e704817627a5618"
   },
   "source": [
    "Let's go through this bit by bit.\n",
    "\n",
    "```python\n",
    "class Network(nn.Module):\n",
    "```\n",
    "\n",
    "Here we're inheriting from `nn.Module`. Combined with `super().__init__()` this creates a class that tracks the architecture and provides a lot of useful methods and attributes. It is mandatory to inherit from `nn.Module` when you're creating a class for your network. The name of the class itself can be anything.\n",
    "\n",
    "```python\n",
    "self.hidden = nn.Linear(784, 256)\n",
    "```\n",
    "\n",
    "This line creates a module for a linear transformation, $x\\mathbf{W} + b$, with 784 inputs and 256 outputs and assigns it to `self.hidden`. The module automatically creates the weight and bias tensors which we'll use in the `forward` method. You can access the weight and bias tensors once the network once it's create at `net.hidden.weight` and `net.hidden.bias`.\n",
    "\n",
    "```python\n",
    "self.output = nn.Linear(256, 10)\n",
    "```\n",
    "\n",
    "Similarly, this creates another linear transformation with 256 inputs and 10 outputs.\n",
    "\n",
    "```python\n",
    "self.sigmoid = nn.Sigmoid()\n",
    "self.softmax = nn.Softmax(dim=1)\n",
    "```\n",
    "\n",
    "Here I defined operations for the sigmoid activation and softmax output. Setting `dim=1` in `nn.Softmax(dim=1)` calculates softmax across the columns.\n",
    "\n",
    "```python\n",
    "def forward(self, x):\n",
    "```\n",
    "\n",
    "PyTorch networks created with `nn.Module` must have a `forward` method defined. It takes in a tensor `x` and passes it through the operations you defined in the `__init__` method.\n",
    "\n",
    "```python\n",
    "x = self.hidden(x)\n",
    "x = self.sigmoid(x)\n",
    "x = self.output(x)\n",
    "x = self.softmax(x)\n",
    "```\n",
    "\n",
    "Here the input tensor `x` is passed through each operation a reassigned to `x`. We can see that the input tensor goes through the hidden layer, then a sigmoid function, then the output layer, and finally the softmax function. It doesn't matter what you name the variables here, as long as the inputs and outputs of the operations match the network architecture you want to build. The order in which you define things in the `__init__` method doesn't matter, but you'll need to sequence the operations correctly in the `forward` method.\n",
    "\n",
    "Now we can create a `Network` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "36bc9a286ffafd0a0b1ac7890906092965f5fee0"
   },
   "outputs": [],
   "source": [
    "model=Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aae8f6f5e7c42a3df7d79b6e3a20293f3a673b0a"
   },
   "source": [
    "We can define the network somewhat more concisely and clearly using the `torch.nn.functional` module. This is the most common way you'll see networks defined as many operations are simple element-wise functions. We normally import this module as `F`, `import torch.nn.functional as F`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1ebea291b4d96d74d435885e60bc2a792c4abd12"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "41e688fd7486e6ac4ea420cdc23e464a4e2c3432"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 128)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hidden layer with sigmoid activation\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        # Output layer with softmax activation\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "30f4a6c129eb490f265d2570e16f86dc96534952"
   },
   "outputs": [],
   "source": [
    "model=Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c3820bb60313a368c0a3d8322b21b7d8adeafeb"
   },
   "source": [
    "### Initializing weights and biases\n",
    "\n",
    "The weights and bias are automatically initialized for you, but it's possible to customize how they are initialized. The weights and biases are tensors attached to the layer you defined, you can get them with `model.fc1.weight` for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d148d7e2446d76d5ca6a8948d23ec513f103cdba"
   },
   "outputs": [],
   "source": [
    "print(model.hidden.weight,model.hidden.weight.shape)\n",
    "print(model.hidden.bias,model.hidden.bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1a1989c40df55dd4324cad2736e72481c148299d"
   },
   "source": [
    "For custom initialization, we can these tensors in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc98f7292fe8d6f40b1ea58b681acf522f500bb2"
   },
   "outputs": [],
   "source": [
    "# Set biases to all zeros\n",
    "model.hidden.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "354f3f9fbcf8b0c6808394ea97e794b9f43ffe60"
   },
   "outputs": [],
   "source": [
    "# sample from random normal with standard dev = 0.01\n",
    "model.hidden.weight.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e3b948402fbcd6e8529fe5ebcd00347f1db63a1c"
   },
   "outputs": [],
   "source": [
    "netowrk=Network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1eb03d730d47d46308e593ff4debbd6899280bbe"
   },
   "source": [
    "### Forward pass\n",
    "\n",
    "Now that we have a network, let's see what happens when we pass in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "59df5bda3337698adad159777311294b7f8cfce4"
   },
   "outputs": [],
   "source": [
    "# Grab some data \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "\n",
    "# Forward pass through the network\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n",
    "img = images[img_idx]\n",
    "view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2103e632ea834fcbd4741de8b9ee7edace23ba6b"
   },
   "source": [
    "As you can see above, our network has basically no idea what this digit is. It's because we haven't trained it yet, , all the weights are random!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6d611ac89023080d6ee0e42b9369376ed261a777"
   },
   "source": [
    "## Add-on-People from the keras would love this!!!\n",
    "PyTorch provides a convenient way to build networks like this where a tensor is passed sequentially through operations, `nn.Sequential`.\n",
    "Lets try to build the above network using this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e6f5405fe980380825786437c0aa8e94cb8cb92e"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = 784\n",
    "hidden_sizes = [128]\n",
    "output_size = 10\n",
    "\n",
    "model=nn.Sequential(nn.Linear(input_size,hidden_sizes[0]),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_sizes[0],output_size),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Softmax(dim=1))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d461b698ae5973918405c9120db6e94194347a27"
   },
   "outputs": [],
   "source": [
    "# Forward pass through the network and display output\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "view_classify(images[0].view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d137ebac2a3367c41e6c001f2edf2a37b0b22211"
   },
   "source": [
    "### Access Layers of the network\n",
    "We can access layers  by integer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0cf54881f8e022928a962d1d83fd5614a97a039e"
   },
   "outputs": [],
   "source": [
    "print(model[0])\n",
    "model[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0499ff7a787fc1885f5998f81f2395fc6bcc4108"
   },
   "source": [
    "### Ordered Dict- Better way to create a network\n",
    "We can also pass in an `OrderedDict` to name the individual layers and operations, instead of using incremental integers. Note that dictionary keys must be unique, so _each operation must have a different name_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ca7567562b0610e6ec4ec7d98f03032bbe32c061"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('hidden', nn.Linear(input_size, hidden_sizes[0])),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('output', nn.Linear(hidden_sizes[0], output_size)),\n",
    "                      ('softmax', nn.Softmax(dim=1))]))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c67ffda9a2ace0093371017d9abf4bc02a8656dc"
   },
   "source": [
    "### Access Layers using integer or name \n",
    "Now we can access layers  either by integer or name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6da7947d84c734eea2bf19acc3127bdf87ccce1c"
   },
   "outputs": [],
   "source": [
    "print(model[0])\n",
    "print(model.hidden)\n",
    "print(model.hidden.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "df59c9d06c7e7d2ec2b6582c6bb0934e2d49c58f"
   },
   "source": [
    "### Recollect everything \n",
    "Before we go ahead and train a neural network to accuractly predict the numbers appearing in the MNIST images,let us recollect the important modules that is necessary for any model training exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f0df7ddfb84bf00cee50f9b916a9c61f1a65aaa9"
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ff53d2bd4296f89b134eb961832043cce0e43e4d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7a1f47e2928ea88a7c9b45edb08ea75016b6fca6"
   },
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c2c9d59a82c6bce28a611e1f409ced8b4f8fdc39"
   },
   "outputs": [],
   "source": [
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                             transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])])\n",
    "trainset=datasets.MNIST('~/.pytorch/MNIST_data/',train=True,transform=transform,download=True)\n",
    "testset=datasets.MNIST('~/.pytorch/MNIST_data/',train=False,transform=transform,download=True)\n",
    "\n",
    "trainloader=torch.utils.data.DataLoader(trainset,batch_size=64,shuffle=True,num_workers=0)\n",
    "#will explain later\n",
    "testloader=torch.utils.data.DataLoader(testset,batch_size=64,shuffle=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c7161f89857d013b0f837c620c0ed24657bed1b2"
   },
   "source": [
    "#### Build a feedforward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e73fc284a626e4d7bbca629f817585aeb06fdd6"
   },
   "outputs": [],
   "source": [
    "# TODO: Build a feed-forward network in one of the three ways mentioned above:\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dfdb486a01347095c7c8d75de1d5b74443bbfd4f"
   },
   "source": [
    "#### Lets run one image through the network to check our work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0864af9a75655db17435ef4940945a7d9532c671"
   },
   "outputs": [],
   "source": [
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0d9976b19b6ca3910a3a4855754bdc1e3de1f52f"
   },
   "source": [
    "#### Define a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "22466cb3a58aad481e903428de2642ff67e9bc1f"
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2e3bda9d30daf829a8e19537715860ff7c678329"
   },
   "outputs": [],
   "source": [
    "# Calculate the loss with the logits and the labels\n",
    "loss=criterion(logits,labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8a7dd6c45e94460f48dd048b35229f74a399a988"
   },
   "source": [
    "## Autograd\n",
    "\n",
    "Now that we know how to calculate a loss, how do we use it to perform backpropagation? Torch provides a module, `autograd`, for automatically calculating the gradients of tensors. We can use it to calculate the gradients of all our parameters with respect to the loss. Autograd works by keeping track of operations performed on tensors, then going backwards through those operations, calculating gradients along the way.\n",
    "\n",
    "PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set `requires_grad = True` on a tensor. You can do this at creation with the `requires_grad` keyword, or at any time with `x.requires_grad_(True)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d3361f46b9d9dbf06bc4a6b257f472129c2b01e1"
   },
   "source": [
    "Let's see an example to understand it better.Then again we will head back to our modelling task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5ab21186791f7e319778106ca1ffb327d0847e16"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "print(x)\n",
    "y = x**2\n",
    "print(y)\n",
    "## grad_fn shows the function that generated this variable\n",
    "print(y.grad_fn)\n",
    "z = y.mean()\n",
    "print(z)\n",
    "print(x.grad)\n",
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "94d46a1835ad4987ff28365b28ee304d366336dc"
   },
   "source": [
    "## Loss and Autograd together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b0c5e229539704b93a5991c27849bd7b41abae80"
   },
   "outputs": [],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logits = model(images)\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "\n",
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d184b346f9ed4194de74a29675da09076e52e0c4"
   },
   "source": [
    "## Defining the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "efadf9e312ec51f9f36d25f043d011c27f4f8fe2"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "91c0777ba686873bd972d96e384c090c9baae3d8"
   },
   "source": [
    "## Training for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6b6ac5071aad8b3232596ed1d4807d73aab09df3"
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        optimizer.zero_grad()\n",
    "        output=model.forward(images)\n",
    "        # TODO: Training pass\n",
    "        \n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Epoch:{e} Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6d837662f725dc7196ba3d24130aa23090dc1616"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(img)\n",
    "\n",
    "# Output of the network are logits, need to take softmax for probabilities\n",
    "ps = F.softmax(logits, dim=1)\n",
    "#helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "37a44994683bfe1fee884125d2e58ed08b62720b"
   },
   "source": [
    "## Inference and Validation\n",
    "\n",
    "The goal of validation is to measure the model's performance on data that isn't part of the training set. Typically this is just accuracy, the percentage of classes the network predicted correctly. Other options are precision and recall and top-5 error rate. We'll focus on accuracy here. First I'll do a forward pass with one batch from the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e94326ca7cdc742c2c575294d260c257a97cab87"
   },
   "source": [
    "### Inference on a batch of images\n",
    "Let us try to do this for a batch of images.Before that we will make some changes in our architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e4ec78de08b2f24f5032ba181ec7a7d79428261a"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(testloader))\n",
    "images.shape,labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3f2244405b587c87c9347abd1ed4ab150f8d80aa"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(testloader))\n",
    "img = images.view(images.shape[0], 784)\n",
    "# Get the class probabilities\n",
    "ps = torch.exp(model(img))\n",
    "# Make sure the shape is appropriate, we should get 10 class probabilities for 64 examples\n",
    "print(ps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "72a2ebdd77e3380b972e24e1565bc7744beedd27"
   },
   "outputs": [],
   "source": [
    "top_prob,top_class=ps.topk(1,dim=1)\n",
    "top_prob.shape,top_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9f6368720bf311e1ee9977f0f2562a02b1afc12f"
   },
   "outputs": [],
   "source": [
    "top_class.view(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a9a05d7571a12641d0da644ae00b1608346faf6a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame({\"Predicted\":top_class.view(top_class.shape[0]),\"Actual\":labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3f958e5da0aed9b404c743c8798b64e0d4341fdd"
   },
   "outputs": [],
   "source": [
    "equals=top_class == labels.view(*top_class.shape)\n",
    "accuracy=torch.mean(equals.type(torch.FloatTensor))\n",
    "accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "352673a9d93a8f6b52165952364a7793ff43b8f0"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "        # Dropout module with 0.2 drop probability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # Now with dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "\n",
    "        # output so no dropout here\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "\n",
    "        return x\n",
    "        \n",
    "model=Network()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.01)\n",
    "criterion=nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d7ef3898265ce167202ee321100129a95e3b748e"
   },
   "outputs": [],
   "source": [
    "epochs=5\n",
    "train_losses,test_losses=[],[]\n",
    "for e in range(epochs):\n",
    "    running_loss=0\n",
    "    for images,labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        #images=images.view(images.shape[0],-1)\n",
    "        log_ps=model(images)\n",
    "        loss=criterion(log_ps,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss=0\n",
    "        accuracy=0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images,labels in testloader:\n",
    "                log_ps=model(images)\n",
    "                test_loss+=criterion(log_ps,labels)\n",
    "                ps=torch.exp(log_ps)\n",
    "                top_p,top_class=ps.topk(1,dim=1)\n",
    "                equals=top_class==labels.view(*top_class.shape)\n",
    "                accuracy+=torch.mean(equals.type(torch.FloatTensor))\n",
    "        model.train()\n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "086d29056a5322e8c76820fcdc87ddc5424539ff"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5612d928a89de850888b2caa3251617ff1ebc9fc"
   },
   "source": [
    "## Inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e908e92d92cf3f2634fa665acbca4012bacdb3bf"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[0]\n",
    "# Convert 2D image to 1D vector\n",
    "img = img.view(1, 784)\n",
    "\n",
    "# Calculate the class probabilities (softmax) for img\n",
    "with torch.no_grad():\n",
    "    output = model.forward(img)\n",
    "\n",
    "ps = torch.exp(output)\n",
    "top_prob,top_class=ps.topk(1,dim=1)\n",
    "top_class.item(),labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "086a197d3e597422ee8b592832f811444577b876"
   },
   "source": [
    "The parameters for PyTorch networks are stored in a model's state_dict\n",
    " Optimizer objects (torch.optim) also have a state_dict, which contains information about the optimizers state, as well as the hyperparameters used.\n",
    "\n",
    "Because state_dict objects are Python dictionaries, they can be easily saved, updated, altered, and restored, adding a great deal of modularity to PyTorch models and optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2dbde41ca47a505766ec29ad2c89443f9a4d8d7a"
   },
   "outputs": [],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "67e383a0385379d68f1c4f0d38143504b098a8d5"
   },
   "outputs": [],
   "source": [
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "98bee7eaf09d225730006f2b24ca5662d28cfb65"
   },
   "source": [
    "# Multilayered Perceptron (MLP) implemention on  MNIST dataset \n",
    "## Untill now we were using the MNIST dataset that is available in torchvision.dataset.Let us now load the dataset from Kaggle repo and train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4e83a9e422c10eb07cbfb779be01803d2b8a5334"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "PATH=Path(\"../input\")\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "72b61aac15c29fc295d77130b07d1110c9cb1825"
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(PATH/'train.csv')\n",
    "test=pd.read_csv(PATH/\"test.csv\")\n",
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "858a074c0e1dea92562d0f1bd93ff5302f861643"
   },
   "outputs": [],
   "source": [
    "x_train=train.drop(\"label\",axis=1)\n",
    "x_train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6235582187167970fa04cdac0356f8631b74a7b6"
   },
   "outputs": [],
   "source": [
    "y_train=np.array(train['label'])\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b8ff683f50227c31ee39ec05a7bb8b4e2a8c5f94"
   },
   "outputs": [],
   "source": [
    "x_train=x_train/255\n",
    "test=test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a06249ad57104d74d0258fd5972961f720bdc3cf"
   },
   "outputs": [],
   "source": [
    "trainData = torch.from_numpy(x_train.values)\n",
    "trainLabel=torch.from_numpy(y_train)\n",
    "testData = torch.from_numpy(test.values)\n",
    "trainData, testData = trainData.type(torch.FloatTensor), testData.type(torch.FloatTensor)\n",
    "trainData.shape,testData.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "532a1642800e65b38bc8644d42e1020e64d44284"
   },
   "outputs": [],
   "source": [
    "trainData = trainData.unsqueeze_(dim=1)\n",
    "testData = testData.unsqueeze_(dim=1)\n",
    "trainData.shape,testData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ef32713cc5e6738bbe5181a0742db43fe3b5bd40"
   },
   "outputs": [],
   "source": [
    "#transforms =transforms.Compose(transforms.ToTensor())\n",
    "dataset = torch.utils.data.TensorDataset(trainData,torch.from_numpy(y_train))\n",
    "dataloader = torch.utils.data.DataLoader(dataset,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2df4882ed86f9b17b4bba52d56adfde46d1f718d"
   },
   "outputs": [],
   "source": [
    "epochs=5\n",
    "train_losses,test_losses=[],[]\n",
    "for e in range(epochs):\n",
    "    running_loss=0\n",
    "    for images,labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        #images=images.view(images.shape[0],-1)\n",
    "        log_ps=model(images)\n",
    "        loss=criterion(log_ps,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss=0\n",
    "        accuracy=0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images,labels in testloader:\n",
    "                log_ps=model(images)\n",
    "                test_loss+=criterion(log_ps,labels)\n",
    "                ps=torch.exp(log_ps)\n",
    "                top_p,top_class=ps.topk(1,dim=1)\n",
    "                equals=top_class==labels.view(*top_class.shape)\n",
    "                accuracy+=torch.mean(equals.type(torch.FloatTensor))\n",
    "        model.train()\n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "325af77fba5ac76ef1f68cb02275c497c88438ec"
   },
   "source": [
    "Save our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bfcc3f17cadca0bf48cec130586b907965905ed6"
   },
   "outputs": [],
   "source": [
    "print(\"Our model: \\n\\n\", model, '\\n')\n",
    "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f83335753469344d38ac362053a74fad30b0ca3e"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "abd854b1c8bfed532cb4e64578c40fd29dea9a36"
   },
   "outputs": [],
   "source": [
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a889737952161eb1834f521476f0f1c8448570a"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a08eff1adeb3a8f8f7a31356828ee732a557c3d5"
   },
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 784,\n",
    "              'output_size': 10,\n",
    "              'hidden_layers': [256,128,64],\n",
    "              'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Resource \n",
    "\n",
    "[Introduction to Pytorch-Udacity](https://github.com/udacity/deep-learning-v2-pytorch/tree/master/intro-to-pytorch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
